{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6891f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db0960",
   "metadata": {},
   "source": [
    "* 使用PyTorch实现一个学习系统\n",
    "* 理解最基础的nerual networks / deep learning知识\n",
    "\n",
    "AI > Machine Learning > 表示学习（学习数据集的特征）> Deep learning\n",
    "\n",
    "神经网络历史：\n",
    "* 1998 LeNet-5\n",
    "* 2012 AlexNet\n",
    "* 2014 GoogLeNet & VGG\n",
    "* 2015 ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a08a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w= 0.0\n",
      "MSE= 18.666666666666668\n",
      "w= 0.1\n",
      "MSE= 16.846666666666668\n",
      "w= 0.2\n",
      "MSE= 15.120000000000003\n",
      "w= 0.30000000000000004\n",
      "MSE= 13.486666666666665\n",
      "w= 0.4\n",
      "MSE= 11.946666666666667\n",
      "w= 0.5\n",
      "MSE= 10.5\n",
      "w= 0.6000000000000001\n",
      "MSE= 9.146666666666663\n",
      "w= 0.7000000000000001\n",
      "MSE= 7.886666666666666\n",
      "w= 0.8\n",
      "MSE= 6.719999999999999\n",
      "w= 0.9\n",
      "MSE= 5.646666666666666\n",
      "w= 1.0\n",
      "MSE= 4.666666666666667\n",
      "w= 1.1\n",
      "MSE= 3.779999999999999\n",
      "w= 1.2000000000000002\n",
      "MSE= 2.986666666666665\n",
      "w= 1.3\n",
      "MSE= 2.2866666666666657\n",
      "w= 1.4000000000000001\n",
      "MSE= 1.6799999999999995\n",
      "w= 1.5\n",
      "MSE= 1.1666666666666667\n",
      "w= 1.6\n",
      "MSE= 0.746666666666666\n",
      "w= 1.7000000000000002\n",
      "MSE= 0.4199999999999995\n",
      "w= 1.8\n",
      "MSE= 0.1866666666666665\n",
      "w= 1.9000000000000001\n",
      "MSE= 0.046666666666666586\n",
      "w= 2.0\n",
      "MSE= 0.0\n",
      "w= 2.1\n",
      "MSE= 0.046666666666666835\n",
      "w= 2.2\n",
      "MSE= 0.18666666666666698\n",
      "w= 2.3000000000000003\n",
      "MSE= 0.42000000000000054\n",
      "w= 2.4000000000000004\n",
      "MSE= 0.7466666666666679\n",
      "w= 2.5\n",
      "MSE= 1.1666666666666667\n",
      "w= 2.6\n",
      "MSE= 1.6800000000000008\n",
      "w= 2.7\n",
      "MSE= 2.2866666666666693\n",
      "w= 2.8000000000000003\n",
      "MSE= 2.986666666666668\n",
      "w= 2.9000000000000004\n",
      "MSE= 3.780000000000003\n",
      "w= 3.0\n",
      "MSE= 4.666666666666667\n",
      "w= 3.1\n",
      "MSE= 5.646666666666668\n",
      "w= 3.2\n",
      "MSE= 6.720000000000003\n",
      "w= 3.3000000000000003\n",
      "MSE= 7.886666666666668\n",
      "w= 3.4000000000000004\n",
      "MSE= 9.14666666666667\n",
      "w= 3.5\n",
      "MSE= 10.5\n",
      "w= 3.6\n",
      "MSE= 11.94666666666667\n",
      "w= 3.7\n",
      "MSE= 13.486666666666673\n",
      "w= 3.8000000000000003\n",
      "MSE= 15.120000000000005\n",
      "w= 3.9000000000000004\n",
      "MSE= 16.84666666666667\n",
      "w= 4.0\n",
      "MSE= 18.666666666666668\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = [1,2,3]\n",
    "y_data = [2,4,6]\n",
    "\n",
    "def forward(x,w):\n",
    "    return x* w\n",
    "\n",
    "def loss(x,y,w):\n",
    "    y_pred = forward(x,w)\n",
    "    return (y_pred-y)**2\n",
    "\n",
    "w_list = []\n",
    "mse_list = []\n",
    "for w in np.arange(0,4.1,0.1):\n",
    "    print(\"w=\",w)\n",
    "    l_sum = 0\n",
    "    for x_val,y_val in zip(x_data,y_data):\n",
    "        loss_val = loss(x_val,y_val,w)\n",
    "        l_sum += loss_val\n",
    "    print(\"MSE=\",l_sum/len(x_data))\n",
    "    w_list.append(w)\n",
    "    mse_list.append(l_sum/len(x_data))\n",
    "plt.plot(w_list,mse_list)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68be3ee",
   "metadata": {},
   "source": [
    "PyTorch可视化工具visdom\n",
    "\n",
    "\n",
    "3维图：np.meshgrid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d3f5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict(before training) 4 4\n",
      "epoch:  0 w: 1.0933333333333333 loss:  4.666666666666667\n",
      "epoch:  1 w: 1.1779555555555554 loss:  3.8362074074074086\n",
      "epoch:  2 w: 1.2546797037037036 loss:  3.1535329869958857\n",
      "epoch:  3 w: 1.3242429313580246 loss:  2.592344272332262\n",
      "epoch:  4 w: 1.3873135910979424 loss:  2.1310222071581117\n",
      "epoch:  5 w: 1.4444976559288012 loss:  1.7517949663820642\n",
      "epoch:  6 w: 1.4963445413754464 loss:  1.440053319920117\n",
      "epoch:  7 w: 1.5433523841804047 loss:  1.1837878313441108\n",
      "epoch:  8 w: 1.5859728283235668 loss:  0.9731262101573632\n",
      "epoch:  9 w: 1.6246153643467005 loss:  0.7999529948031382\n",
      "epoch:  10 w: 1.659651263674342 loss:  0.6575969151946154\n",
      "epoch:  11 w: 1.6914171457314033 loss:  0.5405738908195378\n",
      "epoch:  12 w: 1.7202182121298057 loss:  0.44437576375991855\n",
      "epoch:  13 w: 1.7463311789976905 loss:  0.365296627844598\n",
      "epoch:  14 w: 1.7700069356245727 loss:  0.3002900634939416\n",
      "epoch:  15 w: 1.7914729549662791 loss:  0.2468517784170642\n",
      "epoch:  16 w: 1.8109354791694263 loss:  0.2029231330489788\n",
      "epoch:  17 w: 1.8285815011136133 loss:  0.16681183417217407\n",
      "epoch:  18 w: 1.8445805610096762 loss:  0.1371267415488235\n",
      "epoch:  19 w: 1.8590863753154396 loss:  0.11272427607497944\n",
      "epoch:  20 w: 1.872238313619332 loss:  0.09266436490145864\n",
      "epoch:  21 w: 1.8841627376815275 loss:  0.07617422636521683\n",
      "epoch:  22 w: 1.8949742154979183 loss:  0.06261859959338009\n",
      "epoch:  23 w: 1.904776622051446 loss:  0.051475271914629306\n",
      "epoch:  24 w: 1.9136641373266443 loss:  0.04231496130368814\n",
      "epoch:  25 w: 1.9217221511761575 loss:  0.03478477885657844\n",
      "epoch:  26 w: 1.9290280837330496 loss:  0.02859463421027894\n",
      "epoch:  27 w: 1.9356521292512983 loss:  0.023506060193480772\n",
      "epoch:  28 w: 1.9416579305211772 loss:  0.01932302619282764\n",
      "epoch:  29 w: 1.9471031903392007 loss:  0.015884386331668398\n",
      "epoch:  30 w: 1.952040225907542 loss:  0.01305767153735723\n",
      "epoch:  31 w: 1.9565164714895047 loss:  0.010733986344664803\n",
      "epoch:  32 w: 1.9605749341504843 loss:  0.008823813841374291\n",
      "epoch:  33 w: 1.9642546069631057 loss:  0.007253567147113681\n",
      "epoch:  34 w: 1.9675908436465492 loss:  0.005962754575689583\n",
      "epoch:  35 w: 1.970615698239538 loss:  0.004901649272531298\n",
      "epoch:  36 w: 1.9733582330705144 loss:  0.004029373553099482\n",
      "epoch:  37 w: 1.975844797983933 loss:  0.0033123241439168096\n",
      "epoch:  38 w: 1.9780992835054327 loss:  0.0027228776607060357\n",
      "epoch:  39 w: 1.980143350378259 loss:  0.002238326453885249\n",
      "epoch:  40 w: 1.9819966376762883 loss:  0.001840003826269386\n",
      "epoch:  41 w: 1.983676951493168 loss:  0.0015125649231412608\n",
      "epoch:  42 w: 1.9852004360204722 loss:  0.0012433955919298103\n",
      "epoch:  43 w: 1.9865817286585614 loss:  0.0010221264385926248\n",
      "epoch:  44 w: 1.987834100650429 loss:  0.0008402333603648631\n",
      "epoch:  45 w: 1.9889695845897222 loss:  0.0006907091659248264\n",
      "epoch:  46 w: 1.9899990900280147 loss:  0.0005677936325753796\n",
      "epoch:  47 w: 1.9909325082920666 loss:  0.0004667516012495216\n",
      "epoch:  48 w: 1.9917788075181404 loss:  0.000383690560742734\n",
      "epoch:  49 w: 1.9925461188164473 loss:  0.00031541069384432885\n",
      "epoch:  50 w: 1.9932418143935788 loss:  0.0002592816085930997\n",
      "epoch:  51 w: 1.9938725783835114 loss:  0.0002131410058905752\n",
      "epoch:  52 w: 1.994444471067717 loss:  0.00017521137977565514\n",
      "epoch:  53 w: 1.9949629871013967 loss:  0.0001440315413480261\n",
      "epoch:  54 w: 1.9954331083052663 loss:  0.0001184003283899171\n",
      "epoch:  55 w: 1.9958593515301082 loss:  9.733033217332803e-05\n",
      "epoch:  56 w: 1.9962458120539648 loss:  8.000985883901657e-05\n",
      "epoch:  57 w: 1.9965962029289281 loss:  6.57716599593935e-05\n",
      "epoch:  58 w: 1.9969138906555615 loss:  5.406722767150764e-05\n",
      "epoch:  59 w: 1.997201927527709 loss:  4.444566413387458e-05\n",
      "epoch:  60 w: 1.9974630809584561 loss:  3.65363112808981e-05\n",
      "epoch:  61 w: 1.9976998600690001 loss:  3.0034471708953996e-05\n",
      "epoch:  62 w: 1.9979145397958935 loss:  2.4689670610172655e-05\n",
      "epoch:  63 w: 1.9981091827482769 loss:  2.0296006560253656e-05\n",
      "epoch:  64 w: 1.9982856590251044 loss:  1.6684219437262796e-05\n",
      "epoch:  65 w: 1.9984456641827613 loss:  1.3715169898293847e-05\n",
      "epoch:  66 w: 1.9985907355257035 loss:  1.1274479219506377e-05\n",
      "epoch:  67 w: 1.9987222668766378 loss:  9.268123006398985e-06\n",
      "epoch:  68 w: 1.9988415219681517 loss:  7.61880902783969e-06\n",
      "epoch:  69 w: 1.9989496465844576 loss:  6.262999634617916e-06\n",
      "epoch:  70 w: 1.9990476795699081 loss:  5.1484640551938914e-06\n",
      "epoch:  71 w: 1.9991365628100501 loss:  4.232266273994499e-06\n",
      "epoch:  72 w: 1.999217150281112 loss:  3.479110977946351e-06\n",
      "epoch:  73 w: 1.999290216254875 loss:  2.859983851026929e-06\n",
      "epoch:  74 w: 1.9993564627377531 loss:  2.3510338359374262e-06\n",
      "epoch:  75 w: 1.9994165262155628 loss:  1.932654303533636e-06\n",
      "epoch:  76 w: 1.999470983768777 loss:  1.5887277332523938e-06\n",
      "epoch:  77 w: 1.9995203586170245 loss:  1.3060048068548734e-06\n",
      "epoch:  78 w: 1.9995651251461022 loss:  1.0735939958924364e-06\n",
      "epoch:  79 w: 1.9996057134657994 loss:  8.825419799121559e-07\n",
      "epoch:  80 w: 1.9996425135423248 loss:  7.254887315754342e-07\n",
      "epoch:  81 w: 1.999675878945041 loss:  5.963839812987369e-07\n",
      "epoch:  82 w: 1.999706130243504 loss:  4.902541385825727e-07\n",
      "epoch:  83 w: 1.9997335580874436 loss:  4.0301069098738336e-07\n",
      "epoch:  84 w: 1.9997584259992822 loss:  3.312926995781724e-07\n",
      "epoch:  85 w: 1.9997809729060159 loss:  2.723373231729343e-07\n",
      "epoch:  86 w: 1.9998014154347876 loss:  2.2387338352920307e-07\n",
      "epoch:  87 w: 1.9998199499942075 loss:  1.8403387118941732e-07\n",
      "epoch:  88 w: 1.9998367546614149 loss:  1.5128402140063082e-07\n",
      "epoch:  89 w: 1.9998519908930161 loss:  1.2436218932547864e-07\n",
      "epoch:  90 w: 1.9998658050763347 loss:  1.0223124683409346e-07\n",
      "epoch:  91 w: 1.9998783299358769 loss:  8.403862850836479e-08\n",
      "epoch:  92 w: 1.9998896858085284 loss:  6.908348768398496e-08\n",
      "epoch:  93 w: 1.9998999817997325 loss:  5.678969725349543e-08\n",
      "epoch:  94 w: 1.9999093168317574 loss:  4.66836551287917e-08\n",
      "epoch:  95 w: 1.9999177805941268 loss:  3.8376039345125727e-08\n",
      "epoch:  96 w: 1.9999254544053418 loss:  3.154680994333735e-08\n",
      "epoch:  97 w: 1.9999324119941766 loss:  2.593287985380858e-08\n",
      "epoch:  98 w: 1.9999387202080534 loss:  2.131797981222471e-08\n",
      "epoch:  99 w: 1.9999444396553017 loss:  1.752432687141379e-08\n",
      "Predict(after training) 4 7.999777758621207\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = [1,2,3]\n",
    "y_data = [2,4,6]\n",
    "\n",
    "w = 1\n",
    "\n",
    "def forward(x):\n",
    "    return x * w\n",
    "\n",
    "def cost(xs,ys):\n",
    "    cost = 0\n",
    "    for x_val,y_val in zip(xs,ys):\n",
    "        y_pred = forward(x_val)\n",
    "        cost += (y_pred-y_val)**2\n",
    "    return cost/len(xs)\n",
    "\n",
    "def gradient(xs,ys):\n",
    "    grad = 0\n",
    "    \n",
    "    # 损失对梯度求导，化简得到如下公式\n",
    "    for x,y in zip(xs,ys):\n",
    "        grad += 2*x*(x*w-y)\n",
    "    return grad / len(xs)\n",
    "\n",
    "print(\"Predict(before training)\",4,forward(4))\n",
    "\n",
    "cost_val_list = []\n",
    "epoch_list = []\n",
    "for epoch in range(100):\n",
    "    cost_val = cost(x_data,y_data)\n",
    "    cost_val_list.append(cost_val)\n",
    "    epoch_list.append(epoch)\n",
    "    \n",
    "    grad_val = gradient(x_data,y_data)\n",
    "    w -= 0.01* grad_val \n",
    "    \n",
    "    print(\"epoch: \",epoch,\"w:\",w,\"loss: \",cost_val)\n",
    "\n",
    "print(\"Predict(after training)\",4,forward(4))\n",
    "\n",
    "plt.plot(epoch_list,cost_val_list)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c89b9e0",
   "metadata": {},
   "source": [
    "* 随机梯度下降法，在每个epoch内，对于每个样本更新一次梯度\n",
    "* Mini-Batch 随机梯度下降，在每个epoch内，用每个Batch更新一次梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c80ac",
   "metadata": {},
   "source": [
    "最基本的对象是Tensor，用来存储数据。包括data和grad。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4189b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: 1 2 -2.0\n",
      "grad: 2 4 -7.840000152587891\n",
      "grad: 3 6 -16.228801727294922\n",
      "progress: 0 <built-in method item of Tensor object at 0x0000025F0E2AB180>\n",
      "grad: 1 2 -1.478623867034912\n",
      "grad: 2 4 -5.796205520629883\n",
      "grad: 3 6 -11.998146057128906\n",
      "progress: 1 <built-in method item of Tensor object at 0x0000025F0E2AB3B0>\n",
      "grad: 1 2 -1.0931644439697266\n",
      "grad: 2 4 -4.285204887390137\n",
      "grad: 3 6 -8.870372772216797\n",
      "progress: 2 <built-in method item of Tensor object at 0x0000025F0E2AB0E0>\n",
      "grad: 1 2 -0.8081896305084229\n",
      "grad: 2 4 -3.1681032180786133\n",
      "grad: 3 6 -6.557973861694336\n",
      "progress: 3 <built-in method item of Tensor object at 0x0000025F0E276950>\n",
      "grad: 1 2 -0.5975041389465332\n",
      "grad: 2 4 -2.3422164916992188\n",
      "grad: 3 6 -4.848389625549316\n",
      "progress: 4 <built-in method item of Tensor object at 0x0000025F0E276220>\n",
      "grad: 1 2 -0.4417421817779541\n",
      "grad: 2 4 -1.7316293716430664\n",
      "grad: 3 6 -3.58447265625\n",
      "progress: 5 <built-in method item of Tensor object at 0x0000025F0E276950>\n",
      "grad: 1 2 -0.3265852928161621\n",
      "grad: 2 4 -1.2802143096923828\n",
      "grad: 3 6 -2.650045394897461\n",
      "progress: 6 <built-in method item of Tensor object at 0x0000025F0E2956D0>\n",
      "grad: 1 2 -0.24144840240478516\n",
      "grad: 2 4 -0.9464778900146484\n",
      "grad: 3 6 -1.9592113494873047\n",
      "progress: 7 <built-in method item of Tensor object at 0x0000025F0E2956D0>\n",
      "grad: 1 2 -0.17850565910339355\n",
      "grad: 2 4 -0.699742317199707\n",
      "grad: 3 6 -1.4484672546386719\n",
      "progress: 8 <built-in method item of Tensor object at 0x0000025F0E295770>\n",
      "grad: 1 2 -0.1319713592529297\n",
      "grad: 2 4 -0.5173273086547852\n",
      "grad: 3 6 -1.070866584777832\n",
      "progress: 9 <built-in method item of Tensor object at 0x0000025F0E295680>\n",
      "grad: 1 2 -0.09756779670715332\n",
      "grad: 2 4 -0.3824653625488281\n",
      "grad: 3 6 -0.7917022705078125\n",
      "progress: 10 <built-in method item of Tensor object at 0x0000025F0E295400>\n",
      "grad: 1 2 -0.07213282585144043\n",
      "grad: 2 4 -0.2827606201171875\n",
      "grad: 3 6 -0.5853137969970703\n",
      "progress: 11 <built-in method item of Tensor object at 0x0000025F0E295540>\n",
      "grad: 1 2 -0.053328514099121094\n",
      "grad: 2 4 -0.2090473175048828\n",
      "grad: 3 6 -0.43272972106933594\n",
      "progress: 12 <built-in method item of Tensor object at 0x0000025F0E295BD0>\n",
      "grad: 1 2 -0.039426326751708984\n",
      "grad: 2 4 -0.15455150604248047\n",
      "grad: 3 6 -0.3199195861816406\n",
      "progress: 13 <built-in method item of Tensor object at 0x0000025F0E295A90>\n",
      "grad: 1 2 -0.029148340225219727\n",
      "grad: 2 4 -0.11426162719726562\n",
      "grad: 3 6 -0.23652076721191406\n",
      "progress: 14 <built-in method item of Tensor object at 0x0000025F0E295A40>\n",
      "grad: 1 2 -0.021549701690673828\n",
      "grad: 2 4 -0.08447456359863281\n",
      "grad: 3 6 -0.17486286163330078\n",
      "progress: 15 <built-in method item of Tensor object at 0x0000025F0E295720>\n",
      "grad: 1 2 -0.01593184471130371\n",
      "grad: 2 4 -0.062453269958496094\n",
      "grad: 3 6 -0.12927818298339844\n",
      "progress: 16 <built-in method item of Tensor object at 0x0000025F0E295900>\n",
      "grad: 1 2 -0.011778593063354492\n",
      "grad: 2 4 -0.046172142028808594\n",
      "grad: 3 6 -0.09557533264160156\n",
      "progress: 17 <built-in method item of Tensor object at 0x0000025F0E295B30>\n",
      "grad: 1 2 -0.00870823860168457\n",
      "grad: 2 4 -0.03413581848144531\n",
      "grad: 3 6 -0.07066154479980469\n",
      "progress: 18 <built-in method item of Tensor object at 0x0000025F0E295AE0>\n",
      "grad: 1 2 -0.006437778472900391\n",
      "grad: 2 4 -0.025236129760742188\n",
      "grad: 3 6 -0.052239418029785156\n",
      "progress: 19 <built-in method item of Tensor object at 0x0000025F0E295DB0>\n",
      "grad: 1 2 -0.004759550094604492\n",
      "grad: 2 4 -0.018657684326171875\n",
      "grad: 3 6 -0.038620948791503906\n",
      "progress: 20 <built-in method item of Tensor object at 0x0000025F0E295E00>\n",
      "grad: 1 2 -0.003518819808959961\n",
      "grad: 2 4 -0.0137939453125\n",
      "grad: 3 6 -0.028553009033203125\n",
      "progress: 21 <built-in method item of Tensor object at 0x0000025F0E295F90>\n",
      "grad: 1 2 -0.00260162353515625\n",
      "grad: 2 4 -0.010198593139648438\n",
      "grad: 3 6 -0.021108627319335938\n",
      "progress: 22 <built-in method item of Tensor object at 0x0000025F0E2AB4A0>\n",
      "grad: 1 2 -0.0019233226776123047\n",
      "grad: 2 4 -0.0075397491455078125\n",
      "grad: 3 6 -0.0156097412109375\n",
      "progress: 23 <built-in method item of Tensor object at 0x0000025F0E2AB450>\n",
      "grad: 1 2 -0.0014221668243408203\n",
      "grad: 2 4 -0.0055751800537109375\n",
      "grad: 3 6 -0.011541366577148438\n",
      "progress: 24 <built-in method item of Tensor object at 0x0000025F0E2AB4A0>\n",
      "grad: 1 2 -0.0010514259338378906\n",
      "grad: 2 4 -0.0041217803955078125\n",
      "grad: 3 6 -0.008531570434570312\n",
      "progress: 25 <built-in method item of Tensor object at 0x0000025F0E276400>\n",
      "grad: 1 2 -0.0007772445678710938\n",
      "grad: 2 4 -0.0030469894409179688\n",
      "grad: 3 6 -0.006305694580078125\n",
      "progress: 26 <built-in method item of Tensor object at 0x0000025F0E276450>\n",
      "grad: 1 2 -0.0005745887756347656\n",
      "grad: 2 4 -0.0022525787353515625\n",
      "grad: 3 6 -0.0046634674072265625\n",
      "progress: 27 <built-in method item of Tensor object at 0x0000025F0E276A40>\n",
      "grad: 1 2 -0.0004248619079589844\n",
      "grad: 2 4 -0.0016651153564453125\n",
      "grad: 3 6 -0.003444671630859375\n",
      "progress: 28 <built-in method item of Tensor object at 0x0000025F0E2952C0>\n",
      "grad: 1 2 -0.0003139972686767578\n",
      "grad: 2 4 -0.0012311935424804688\n",
      "grad: 3 6 -0.0025491714477539062\n",
      "progress: 29 <built-in method item of Tensor object at 0x0000025F0E2956D0>\n",
      "grad: 1 2 -0.00023221969604492188\n",
      "grad: 2 4 -0.0009107589721679688\n",
      "grad: 3 6 -0.0018854141235351562\n",
      "progress: 30 <built-in method item of Tensor object at 0x0000025F0E295770>\n",
      "grad: 1 2 -0.00017189979553222656\n",
      "grad: 2 4 -0.0006742477416992188\n",
      "grad: 3 6 -0.00139617919921875\n",
      "progress: 31 <built-in method item of Tensor object at 0x0000025F0E2951D0>\n",
      "grad: 1 2 -0.0001270771026611328\n",
      "grad: 2 4 -0.0004978179931640625\n",
      "grad: 3 6 -0.00102996826171875\n",
      "progress: 32 <built-in method item of Tensor object at 0x0000025F0E295C20>\n",
      "grad: 1 2 -9.393692016601562e-05\n",
      "grad: 2 4 -0.0003681182861328125\n",
      "grad: 3 6 -0.0007610321044921875\n",
      "progress: 33 <built-in method item of Tensor object at 0x0000025F0E295400>\n",
      "grad: 1 2 -6.937980651855469e-05\n",
      "grad: 2 4 -0.00027179718017578125\n",
      "grad: 3 6 -0.000560760498046875\n",
      "progress: 34 <built-in method item of Tensor object at 0x0000025F0E295BD0>\n",
      "grad: 1 2 -5.125999450683594e-05\n",
      "grad: 2 4 -0.00020122528076171875\n",
      "grad: 3 6 -0.0004177093505859375\n",
      "progress: 35 <built-in method item of Tensor object at 0x0000025F0E295950>\n",
      "grad: 1 2 -3.790855407714844e-05\n",
      "grad: 2 4 -0.000148773193359375\n",
      "grad: 3 6 -0.000308990478515625\n",
      "progress: 36 <built-in method item of Tensor object at 0x0000025F0E2957C0>\n",
      "grad: 1 2 -2.8133392333984375e-05\n",
      "grad: 2 4 -0.000110626220703125\n",
      "grad: 3 6 -0.0002288818359375\n",
      "progress: 37 <built-in method item of Tensor object at 0x0000025F0E295720>\n",
      "grad: 1 2 -2.09808349609375e-05\n",
      "grad: 2 4 -8.20159912109375e-05\n",
      "grad: 3 6 -0.00016880035400390625\n",
      "progress: 38 <built-in method item of Tensor object at 0x0000025F0E295590>\n",
      "grad: 1 2 -1.5497207641601562e-05\n",
      "grad: 2 4 -6.103515625e-05\n",
      "grad: 3 6 -0.000125885009765625\n",
      "progress: 39 <built-in method item of Tensor object at 0x0000025F0E295900>\n",
      "grad: 1 2 -1.1444091796875e-05\n",
      "grad: 2 4 -4.482269287109375e-05\n",
      "grad: 3 6 -9.1552734375e-05\n",
      "progress: 40 <built-in method item of Tensor object at 0x0000025F0E295A40>\n",
      "grad: 1 2 -8.344650268554688e-06\n",
      "grad: 2 4 -3.24249267578125e-05\n",
      "grad: 3 6 -6.580352783203125e-05\n",
      "progress: 41 <built-in method item of Tensor object at 0x0000025F0E295D60>\n",
      "grad: 1 2 -5.9604644775390625e-06\n",
      "grad: 2 4 -2.288818359375e-05\n",
      "grad: 3 6 -4.57763671875e-05\n",
      "progress: 42 <built-in method item of Tensor object at 0x0000025F0E295810>\n",
      "grad: 1 2 -4.291534423828125e-06\n",
      "grad: 2 4 -1.71661376953125e-05\n",
      "grad: 3 6 -3.719329833984375e-05\n",
      "progress: 43 <built-in method item of Tensor object at 0x0000025F0E295CC0>\n",
      "grad: 1 2 -3.337860107421875e-06\n",
      "grad: 2 4 -1.33514404296875e-05\n",
      "grad: 3 6 -2.86102294921875e-05\n",
      "progress: 44 <built-in method item of Tensor object at 0x0000025F0E2B6860>\n",
      "grad: 1 2 -2.6226043701171875e-06\n",
      "grad: 2 4 -1.049041748046875e-05\n",
      "grad: 3 6 -2.288818359375e-05\n",
      "progress: 45 <built-in method item of Tensor object at 0x0000025F0E2B6860>\n",
      "grad: 1 2 -1.9073486328125e-06\n",
      "grad: 2 4 -7.62939453125e-06\n",
      "grad: 3 6 -1.430511474609375e-05\n",
      "progress: 46 <built-in method item of Tensor object at 0x0000025F0CF34E00>\n",
      "grad: 1 2 -1.430511474609375e-06\n",
      "grad: 2 4 -5.7220458984375e-06\n",
      "grad: 3 6 -1.1444091796875e-05\n",
      "progress: 47 <built-in method item of Tensor object at 0x0000025F0E2ABC70>\n",
      "grad: 1 2 -1.1920928955078125e-06\n",
      "grad: 2 4 -4.76837158203125e-06\n",
      "grad: 3 6 -1.1444091796875e-05\n",
      "progress: 48 <built-in method item of Tensor object at 0x0000025F0E2AB450>\n",
      "grad: 1 2 -9.5367431640625e-07\n",
      "grad: 2 4 -3.814697265625e-06\n",
      "grad: 3 6 -8.58306884765625e-06\n",
      "progress: 49 <built-in method item of Tensor object at 0x0000025F0E2AB4A0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 50 <built-in method item of Tensor object at 0x0000025F0E2766D0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 51 <built-in method item of Tensor object at 0x0000025F0E276950>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 52 <built-in method item of Tensor object at 0x0000025F0E276400>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 53 <built-in method item of Tensor object at 0x0000025F0E2959A0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 54 <built-in method item of Tensor object at 0x0000025F0E295D10>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 55 <built-in method item of Tensor object at 0x0000025F0E295680>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 56 <built-in method item of Tensor object at 0x0000025F0E295090>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 57 <built-in method item of Tensor object at 0x0000025F0E295540>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 58 <built-in method item of Tensor object at 0x0000025F0E295130>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 59 <built-in method item of Tensor object at 0x0000025F0E295220>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 60 <built-in method item of Tensor object at 0x0000025F0E295C20>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 61 <built-in method item of Tensor object at 0x0000025F0E295720>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 62 <built-in method item of Tensor object at 0x0000025F0E2954A0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 63 <built-in method item of Tensor object at 0x0000025F0E295B30>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 64 <built-in method item of Tensor object at 0x0000025F0E295310>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 65 <built-in method item of Tensor object at 0x0000025F0E295AE0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 66 <built-in method item of Tensor object at 0x0000025F0E295E50>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 67 <built-in method item of Tensor object at 0x0000025F0E295CC0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 68 <built-in method item of Tensor object at 0x0000025F0E2953B0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 69 <built-in method item of Tensor object at 0x0000025F0E2ABC70>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 70 <built-in method item of Tensor object at 0x0000025F0E2AB450>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 71 <built-in method item of Tensor object at 0x0000025F0E2AB3B0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 72 <built-in method item of Tensor object at 0x0000025F0E276310>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 73 <built-in method item of Tensor object at 0x0000025F0E276450>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 74 <built-in method item of Tensor object at 0x0000025F0E276B30>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 75 <built-in method item of Tensor object at 0x0000025F0E295360>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 76 <built-in method item of Tensor object at 0x0000025F0E295D10>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 77 <built-in method item of Tensor object at 0x0000025F0E2952C0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 78 <built-in method item of Tensor object at 0x0000025F0E295090>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 79 <built-in method item of Tensor object at 0x0000025F0E2950E0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 80 <built-in method item of Tensor object at 0x0000025F0E295400>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 81 <built-in method item of Tensor object at 0x0000025F0E295220>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 82 <built-in method item of Tensor object at 0x0000025F0E2957C0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 83 <built-in method item of Tensor object at 0x0000025F0E295130>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 84 <built-in method item of Tensor object at 0x0000025F0E295450>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 85 <built-in method item of Tensor object at 0x0000025F0E2954F0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 86 <built-in method item of Tensor object at 0x0000025F0E295310>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 87 <built-in method item of Tensor object at 0x0000025F0E295D60>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 88 <built-in method item of Tensor object at 0x0000025F0E295810>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 89 <built-in method item of Tensor object at 0x0000025F0E2958B0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 90 <built-in method item of Tensor object at 0x0000025F0E295810>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 91 <built-in method item of Tensor object at 0x0000025F0E2B6860>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 92 <built-in method item of Tensor object at 0x0000025F0E2AB0E0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 93 <built-in method item of Tensor object at 0x0000025F0E2AB0E0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 94 <built-in method item of Tensor object at 0x0000025F0E2AB4A0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 95 <built-in method item of Tensor object at 0x0000025F0E276950>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 96 <built-in method item of Tensor object at 0x0000025F0E276400>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 97 <built-in method item of Tensor object at 0x0000025F0E276220>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 98 <built-in method item of Tensor object at 0x0000025F0E295CC0>\n",
      "grad: 1 2 -7.152557373046875e-07\n",
      "grad: 2 4 -2.86102294921875e-06\n",
      "grad: 3 6 -5.7220458984375e-06\n",
      "progress: 99 <built-in method item of Tensor object at 0x0000025F0E2953B0>\n",
      "Predict(after training) 4 7.999998569488525\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_data = [1,2,3]\n",
    "y_data = [2,4,6]\n",
    "\n",
    "w = torch.Tensor([1.0])\n",
    "w.requires_grad = True \n",
    "\n",
    "def forward(x):\n",
    "    return x * w #x自动类型转化为Tensor\n",
    "\n",
    "# 构建计算图\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred-y)**2\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x,y in zip(x_data,y_data):\n",
    "        l = loss(x,y) # Forward compute the loss\n",
    "        l.backward() # l 即loss现在是一个张量Tensor,调用backward可以把梯度都求出来，\n",
    "        # 求出来之后存在需要梯度的变量中（这里是w），释放计算图\n",
    "        print(\"grad:\",x,y,w.grad.item()) # item，值以标量形式取出来\n",
    "        w.data = w.data - 0.01 * w.grad.data #grad也是一个Tensor，所以必须取到值，只进行数值更新\n",
    "        \n",
    "        w.grad.data.zero_() #梯度值清零，不清零就会累加\n",
    "    print(\"progress:\",epoch,l.item)\n",
    "\n",
    "\n",
    "print(\"Predict(after training)\",4,forward(4).item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb7c32",
   "metadata": {},
   "source": [
    "## 用PyTorch实现线性回归\n",
    "1. 准备数据集\n",
    "2. 设计模型\n",
    "3. 构造损失函数和优化器\n",
    "4. 训练周期：forward backward update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2333ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28.75530433654785\n",
      "1 13.294954299926758\n",
      "2 6.405348777770996\n",
      "3 3.331295967102051\n",
      "4 1.955918312072754\n",
      "5 1.3368438482284546\n",
      "6 1.0545504093170166\n",
      "7 0.9222782850265503\n",
      "8 0.8568872213363647\n",
      "9 0.8213627338409424\n",
      "10 0.7992258667945862\n",
      "11 0.7831403017044067\n",
      "12 0.7698376774787903\n",
      "13 0.7578622102737427\n",
      "14 0.7465647459030151\n",
      "15 0.7356551885604858\n",
      "16 0.7250020503997803\n",
      "17 0.7145463228225708\n",
      "18 0.7042620182037354\n",
      "19 0.6941332817077637\n",
      "20 0.6841545104980469\n",
      "21 0.6743206977844238\n",
      "22 0.6646289825439453\n",
      "23 0.6550768613815308\n",
      "24 0.645662248134613\n",
      "25 0.6363823413848877\n",
      "26 0.6272370219230652\n",
      "27 0.618222713470459\n",
      "28 0.6093379259109497\n",
      "29 0.6005805134773254\n",
      "30 0.5919494032859802\n",
      "31 0.5834417939186096\n",
      "32 0.5750572085380554\n",
      "33 0.566792905330658\n",
      "34 0.5586469769477844\n",
      "35 0.5506184101104736\n",
      "36 0.542704701423645\n",
      "37 0.5349050164222717\n",
      "38 0.5272178053855896\n",
      "39 0.5196410417556763\n",
      "40 0.5121729373931885\n",
      "41 0.5048122406005859\n",
      "42 0.49755722284317017\n",
      "43 0.49040618538856506\n",
      "44 0.4833584725856781\n",
      "45 0.47641199827194214\n",
      "46 0.46956539154052734\n",
      "47 0.46281683444976807\n",
      "48 0.45616525411605835\n",
      "49 0.4496093988418579\n",
      "50 0.44314804673194885\n",
      "51 0.4367793798446655\n",
      "52 0.4305018186569214\n",
      "53 0.42431506514549255\n",
      "54 0.41821688413619995\n",
      "55 0.41220638155937195\n",
      "56 0.40628233551979065\n",
      "57 0.40044382214546204\n",
      "58 0.39468860626220703\n",
      "59 0.38901636004447937\n",
      "60 0.3834258019924164\n",
      "61 0.37791502475738525\n",
      "62 0.3724837899208069\n",
      "63 0.3671306371688843\n",
      "64 0.36185410618782043\n",
      "65 0.35665416717529297\n",
      "66 0.35152843594551086\n",
      "67 0.34647634625434875\n",
      "68 0.34149691462516785\n",
      "69 0.3365890085697174\n",
      "70 0.3317517936229706\n",
      "71 0.32698380947113037\n",
      "72 0.3222848176956177\n",
      "73 0.31765294075012207\n",
      "74 0.3130876123905182\n",
      "75 0.3085882365703583\n",
      "76 0.3041532635688782\n",
      "77 0.2997819185256958\n",
      "78 0.29547375440597534\n",
      "79 0.29122740030288696\n",
      "80 0.28704190254211426\n",
      "81 0.28291645646095276\n",
      "82 0.2788506746292114\n",
      "83 0.27484309673309326\n",
      "84 0.2708931863307953\n",
      "85 0.2669999599456787\n",
      "86 0.2631630599498749\n",
      "87 0.2593808174133301\n",
      "88 0.25565293431282043\n",
      "89 0.25197896361351013\n",
      "90 0.24835757911205292\n",
      "91 0.24478831887245178\n",
      "92 0.24127033352851868\n",
      "93 0.23780281841754913\n",
      "94 0.23438549041748047\n",
      "95 0.23101679980754852\n",
      "96 0.22769667208194733\n",
      "97 0.2244243025779724\n",
      "98 0.22119919955730438\n",
      "99 0.21801996231079102\n",
      "w= 1.6891576051712036\n",
      "b= 0.7066177725791931\n",
      "y_pred =  7.463248252868652\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x_data = torch.Tensor([[1],[2],[3]])  # 初始化为一个3*1的矩阵\n",
    "y_data = torch.Tensor([[2],[4],[6]])\n",
    "\n",
    "# 将模型定义成一个类，继承自torch.nn.Module，需要实现init和forward两个函数\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel,self).__init__() #调用父类的构造，必须要有\n",
    "        self.linear = torch.nn.Linear(1,1) #Linear对象中包含了weight和bias这两个Tensor,自动实现wx+b\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        y_pred = self.linear(x) #可以直接计算wx+b\n",
    "        return y_pred\n",
    "\n",
    "model = LinearModel()\n",
    "\n",
    "# 构造损失函数和优化器\n",
    "# 这里损失函数用MSE   torch.nn.MSELoss(size_average=True,reduce=True) reduce是否需要将所有loss加起来\n",
    "criterion = torch.nn.MSELoss(size_average = False)\n",
    "\n",
    "# optim中有一个类叫SGD torch.optim.SGD() weight_decay(加一个w^Tw的优化目标)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)#告诉优化器对哪些Tensor做梯度优化，由model中的paramenters告知\n",
    "\n",
    "# 训练过程\n",
    "for epoch in range(100):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred,y_data)\n",
    "    print(epoch, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad() #梯度归零\n",
    "    loss.backward() #后向传播\n",
    "    optimizer.step() # 梯度Update\n",
    "\n",
    "# 输出权重和bias\n",
    "print(\"w=\",model.linear.weight.item())\n",
    "print(\"b=\",model.linear.bias.item())\n",
    "\n",
    "# Test Model\n",
    "x_test = torch.Tensor([[4.0]])\n",
    "y_test = model(x_test)\n",
    "print('y_pred = ',y_test.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89df592",
   "metadata": {},
   "source": [
    "nn = nerual network\n",
    "\n",
    "torch.nn.Linear(输入特征维度，输出特征维度，bias = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923f9d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 4)\n",
      "{'x': 3, 'y': 5}\n",
      "Hello1\n"
     ]
    }
   ],
   "source": [
    "def func(*args, **kwargs):\n",
    "    print(args)\n",
    "    print(kwargs)\n",
    "func(1,2,3,4,x=3,y=5)\n",
    "\n",
    "\n",
    "class Foobar:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self,*args,**kwargs):\n",
    "        print(\"Hello\"+str(args[0]))\n",
    "\n",
    "foobar = Foobar()\n",
    "foobar(1,2,3) ##__call__函数使得类的一个实例可以像函数一样被调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e315f515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
